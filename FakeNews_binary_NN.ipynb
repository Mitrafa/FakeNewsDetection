{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsffsTqUtA0l"
      },
      "source": [
        "## Dataset Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "459SpR9NtNsg",
        "outputId": "ee8e66f4-efa6-4560-ff44-758aafb96bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (14716, 1013)\n",
            "X_test shape: (6308, 1013)\n",
            "y_train shape: (14716,)\n",
            "y_test shape: (6308,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = combined_df1_tfidf\n",
        "\n",
        "# Define X (features) and y (target)\n",
        "X = df.drop('label_Fake', axis=1)  # Features (all columns except the target)\n",
        "y = df['label_Fake']  # Target column\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Print the shapes of the resulting datasets\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Netwroks"
      ],
      "metadata": {
        "id": "vkVw8q00uEi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and Evaluate the Initial NN Model"
      ],
      "metadata": {
        "id": "wDrl5Gl5Rg4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Define the Neural Network model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer and the first hidden layer with ReLU activation\n",
        "model.add(Dense(128, input_dim=X_train_resampled.shape[1], activation='relu'))\n",
        "\n",
        "# Second hidden layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer with sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "# - Binary crossentropy is used for binary classification\n",
        "# - Adam optimizer with a learning rate of 0.001\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "# - Use validation_data as the test set to monitor performance\n",
        "model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(\"int32\").ravel()  # Convert probabilities to class labels (0 or 1)\n",
        "\n",
        "# Evaluate the Neural Network model on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Neural Network Model - Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Neural Network Model - Precision: {precision:.4f}\")\n",
        "print(f\"Neural Network Model - Recall: {recall:.4f}\")\n",
        "print(f\"Neural Network Model - F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTYIL0RbuErZ",
        "outputId": "3b42bada-a1ca-4dc7-9578-fd68c44a3975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "554/554 [==============================] - 3s 4ms/step - loss: 0.3869 - accuracy: 0.8224 - val_loss: 0.3388 - val_accuracy: 0.8527\n",
            "Epoch 2/10\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.2750 - accuracy: 0.8827 - val_loss: 0.3166 - val_accuracy: 0.8637\n",
            "Epoch 3/10\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.2175 - accuracy: 0.9122 - val_loss: 0.3252 - val_accuracy: 0.8667\n",
            "Epoch 4/10\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.1577 - accuracy: 0.9390 - val_loss: 0.3685 - val_accuracy: 0.8496\n",
            "Epoch 5/10\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.1045 - accuracy: 0.9627 - val_loss: 0.4225 - val_accuracy: 0.8588\n",
            "Epoch 6/10\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.0693 - accuracy: 0.9767 - val_loss: 0.4897 - val_accuracy: 0.8611\n",
            "Epoch 7/10\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.0495 - accuracy: 0.9830 - val_loss: 0.5451 - val_accuracy: 0.8602\n",
            "Epoch 8/10\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.0385 - accuracy: 0.9876 - val_loss: 0.5975 - val_accuracy: 0.8503\n",
            "Epoch 9/10\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.0294 - accuracy: 0.9895 - val_loss: 0.6522 - val_accuracy: 0.8546\n",
            "Epoch 10/10\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.0226 - accuracy: 0.9909 - val_loss: 0.7213 - val_accuracy: 0.8570\n",
            "198/198 [==============================] - 0s 2ms/step\n",
            "Neural Network Model - Accuracy: 0.8570\n",
            "Neural Network Model - Precision: 0.8572\n",
            "Neural Network Model - Recall: 0.8570\n",
            "Neural Network Model - F1-Score: 0.8571\n",
            "Confusion Matrix:\n",
            "[[3339  460]\n",
            " [ 442 2067]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tune and Evaluate the NN Model"
      ],
      "metadata": {
        "id": "b511BmvrRoHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Define a new Neural Network model with Dropout\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer and first hidden layer with ReLU activation\n",
        "model.add(Dense(128, input_dim=X_train_resampled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.3))  # Add Dropout to prevent overfitting\n",
        "\n",
        "# Second hidden layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer with sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and a lower learning rate\n",
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_resampled, y_train_resampled, epochs=20, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(\"int32\").ravel()\n",
        "\n",
        "# Evaluate the tuned Neural Network model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Tuned Neural Network Model - Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Tuned Neural Network Model - Precision: {precision:.4f}\")\n",
        "print(f\"Tuned Neural Network Model - Recall: {recall:.4f}\")\n",
        "print(f\"Tuned Neural Network Model - F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWHLXrRtmm7M",
        "outputId": "e9f280a7-e372-4799-f049-2239b425b8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "277/277 [==============================] - 2s 5ms/step - loss: 0.5152 - accuracy: 0.7503 - val_loss: 0.3624 - val_accuracy: 0.8408\n",
            "Epoch 2/20\n",
            "277/277 [==============================] - 1s 5ms/step - loss: 0.3470 - accuracy: 0.8476 - val_loss: 0.3395 - val_accuracy: 0.8492\n",
            "Epoch 3/20\n",
            "277/277 [==============================] - 1s 5ms/step - loss: 0.3095 - accuracy: 0.8678 - val_loss: 0.3294 - val_accuracy: 0.8565\n",
            "Epoch 4/20\n",
            "277/277 [==============================] - 1s 4ms/step - loss: 0.2799 - accuracy: 0.8820 - val_loss: 0.3335 - val_accuracy: 0.8546\n",
            "Epoch 5/20\n",
            "277/277 [==============================] - 1s 4ms/step - loss: 0.2545 - accuracy: 0.8950 - val_loss: 0.3291 - val_accuracy: 0.8602\n",
            "Epoch 6/20\n",
            "277/277 [==============================] - 1s 5ms/step - loss: 0.2330 - accuracy: 0.9053 - val_loss: 0.3395 - val_accuracy: 0.8510\n",
            "Epoch 7/20\n",
            "277/277 [==============================] - 1s 4ms/step - loss: 0.2129 - accuracy: 0.9149 - val_loss: 0.3471 - val_accuracy: 0.8567\n",
            "Epoch 8/20\n",
            "277/277 [==============================] - 1s 5ms/step - loss: 0.1866 - accuracy: 0.9278 - val_loss: 0.3479 - val_accuracy: 0.8649\n",
            "Epoch 9/20\n",
            "277/277 [==============================] - 1s 5ms/step - loss: 0.1644 - accuracy: 0.9375 - val_loss: 0.3600 - val_accuracy: 0.8581\n",
            "Epoch 10/20\n",
            "277/277 [==============================] - 1s 5ms/step - loss: 0.1447 - accuracy: 0.9477 - val_loss: 0.3710 - val_accuracy: 0.8667\n",
            "Epoch 11/20\n",
            "277/277 [==============================] - 1s 5ms/step - loss: 0.1299 - accuracy: 0.9545 - val_loss: 0.3772 - val_accuracy: 0.8654\n",
            "Epoch 12/20\n",
            "277/277 [==============================] - 1s 5ms/step - loss: 0.1117 - accuracy: 0.9632 - val_loss: 0.3955 - val_accuracy: 0.8602\n",
            "Epoch 13/20\n",
            "277/277 [==============================] - 1s 4ms/step - loss: 0.0961 - accuracy: 0.9676 - val_loss: 0.4140 - val_accuracy: 0.8559\n",
            "Epoch 14/20\n",
            "277/277 [==============================] - 1s 4ms/step - loss: 0.0883 - accuracy: 0.9722 - val_loss: 0.4327 - val_accuracy: 0.8613\n",
            "Epoch 15/20\n",
            "277/277 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.9765 - val_loss: 0.4596 - val_accuracy: 0.8556\n",
            "Epoch 16/20\n",
            "277/277 [==============================] - 1s 4ms/step - loss: 0.0660 - accuracy: 0.9791 - val_loss: 0.4623 - val_accuracy: 0.8595\n",
            "Epoch 17/20\n",
            "277/277 [==============================] - 1s 5ms/step - loss: 0.0571 - accuracy: 0.9818 - val_loss: 0.4793 - val_accuracy: 0.8610\n",
            "Epoch 18/20\n",
            "277/277 [==============================] - 1s 4ms/step - loss: 0.0529 - accuracy: 0.9817 - val_loss: 0.5001 - val_accuracy: 0.8589\n",
            "Epoch 19/20\n",
            "277/277 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9838 - val_loss: 0.5234 - val_accuracy: 0.8573\n",
            "Epoch 20/20\n",
            "277/277 [==============================] - 1s 5ms/step - loss: 0.0463 - accuracy: 0.9856 - val_loss: 0.5374 - val_accuracy: 0.8573\n",
            "198/198 [==============================] - 0s 2ms/step\n",
            "Tuned Neural Network Model - Accuracy: 0.8573\n",
            "Tuned Neural Network Model - Precision: 0.8571\n",
            "Tuned Neural Network Model - Recall: 0.8573\n",
            "Tuned Neural Network Model - F1-Score: 0.8572\n",
            "Confusion Matrix:\n",
            "[[3365  434]\n",
            " [ 466 2043]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the Fairness of the NN Model"
      ],
      "metadata": {
        "id": "DZqB3mu2Razi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Assuming `sensitive_attr` holds the sensitive attribute 'source_LLM Generated' (0s and 1s)\n",
        "sensitive_attr = X_test['source_LLM Generated']  # Ensure this is the correct column name\n",
        "\n",
        "# Get predictions from the tuned model (already computed as `y_pred`)\n",
        "# y_pred already exists from previous tuned model evaluation code\n",
        "\n",
        "# Split predictions and true labels based on the sensitive attribute\n",
        "y_true_0 = y_test[sensitive_attr == 0]\n",
        "y_pred_0 = y_pred[sensitive_attr == 0]\n",
        "\n",
        "y_true_1 = y_test[sensitive_attr == 1]\n",
        "y_pred_1 = y_pred[sensitive_attr == 1]\n",
        "\n",
        "# 1. Demographic Parity\n",
        "# Proportion of positive predictions for both groups\n",
        "demographic_parity_0 = np.mean(y_pred_0)\n",
        "demographic_parity_1 = np.mean(y_pred_1)\n",
        "demographic_parity_diff = demographic_parity_1 - demographic_parity_0\n",
        "\n",
        "print(f\"Demographic Parity - Group 0: {demographic_parity_0:.4f}, Group 1: {demographic_parity_1:.4f}\")\n",
        "print(f\"Difference in Demographic Parity: {demographic_parity_diff:.4f}\")\n",
        "\n",
        "# 2. Equal Opportunity (True Positive Rate comparison)\n",
        "# TPR for both groups\n",
        "true_positives_0 = np.sum((y_true_0 == 1) & (y_pred_0 == 1))\n",
        "true_positives_1 = np.sum((y_true_1 == 1) & (y_pred_1 == 1))\n",
        "\n",
        "tpr_0 = true_positives_0 / np.sum(y_true_0 == 1)\n",
        "tpr_1 = true_positives_1 / np.sum(y_true_1 == 1)\n",
        "equal_opportunity_diff = tpr_1 - tpr_0\n",
        "\n",
        "print(f\"Equal Opportunity - TPR for Group 0: {tpr_0:.4f}, Group 1: {tpr_1:.4f}\")\n",
        "print(f\"Difference in Equal Opportunity (TPR): {equal_opportunity_diff:.4f}\")\n",
        "\n",
        "# 3. Equalized Odds (TPR and FPR comparison)\n",
        "# FPR for both groups\n",
        "false_positives_0 = np.sum((y_true_0 == 0) & (y_pred_0 == 1))\n",
        "false_positives_1 = np.sum((y_true_1 == 0) & (y_pred_1 == 1))\n",
        "\n",
        "fpr_0 = false_positives_0 / np.sum(y_true_0 == 0)\n",
        "fpr_1 = false_positives_1 / np.sum(y_true_1 == 0)\n",
        "equalized_odds_tpr_diff = tpr_1 - tpr_0\n",
        "equalized_odds_fpr_diff = fpr_0 - fpr_1\n",
        "\n",
        "print(f\"Equalized Odds - TPR for Group 0: {tpr_0:.4f}, Group 1: {tpr_1:.4f}\")\n",
        "print(f\"Equalized Odds - FPR for Group 0: {fpr_0:.4f}, Group 1: {fpr_1:.4f}\")\n",
        "print(f\"Difference in TPR (Equalized Odds): {equalized_odds_tpr_diff:.4f}\")\n",
        "print(f\"Difference in FPR (Equalized Odds): {equalized_odds_fpr_diff:.4f}\")\n",
        "\n",
        "# 4. Predictive Parity (Precision comparison)\n",
        "precision_0 = precision_score(y_true_0, y_pred_0)\n",
        "precision_1 = precision_score(y_true_1, y_pred_1)\n",
        "predictive_parity_diff = precision_1 - precision_0\n",
        "\n",
        "print(f\"Predictive Parity - Precision for Group 0: {precision_0:.4f}, Group 1: {precision_1:.4f}\")\n",
        "print(f\"Difference in Predictive Parity (Precision): {predictive_parity_diff:.4f}\")\n",
        "\n",
        "# Summary of Differences:\n",
        "overall_summary = {\n",
        "    \"Demographic Parity Difference\": demographic_parity_diff,\n",
        "    \"Equal Opportunity (TPR) Difference\": equal_opportunity_diff,\n",
        "    \"Equalized Odds TPR Difference\": equalized_odds_tpr_diff,\n",
        "    \"Equalized Odds FPR Difference\": equalized_odds_fpr_diff,\n",
        "    \"Predictive Parity Difference\": predictive_parity_diff\n",
        "}\n",
        "\n",
        "print(\"\\n=== Overall Fairness Summary ===\")\n",
        "for metric, diff in overall_summary.items():\n",
        "    print(f\"{metric}: {diff:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKE3oC8FZN5l",
        "outputId": "225afd81-e9ac-4578-f167-fbb9fb44c936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demographic Parity - Group 0: 0.3182, Group 1: 0.5044\n",
            "Difference in Demographic Parity: 0.1862\n",
            "Equal Opportunity - TPR for Group 0: 0.6818, Group 1: 0.9421\n",
            "Difference in Equal Opportunity (TPR): 0.2602\n",
            "Equalized Odds - TPR for Group 0: 0.6818, Group 1: 0.9421\n",
            "Equalized Odds - FPR for Group 0: 0.1426, Group 1: 0.0561\n",
            "Difference in TPR (Equalized Odds): 0.2602\n",
            "Difference in FPR (Equalized Odds): 0.0865\n",
            "Predictive Parity - Precision for Group 0: 0.6977, Group 1: 0.9450\n",
            "Difference in Predictive Parity (Precision): 0.2473\n",
            "\n",
            "=== Overall Fairness Summary ===\n",
            "Demographic Parity Difference: 0.1862\n",
            "Equal Opportunity (TPR) Difference: 0.2602\n",
            "Equalized Odds TPR Difference: 0.2602\n",
            "Equalized Odds FPR Difference: 0.0865\n",
            "Predictive Parity Difference: 0.2473\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}